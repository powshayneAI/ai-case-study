# AI and Apple

###### Shayne Powell

## Origin

Apple is a company that was first incorporated on April 1st of 1976, having been developed by **Steve Wozniak** and **Steve Jobs**.

When developed, the goal for Apple was to change the way people viewed computers. They wanted to:
>["Make Computers small enough for people to have them in their homes and offices."](https://guides.loc.gov/this-month-in-business-history/april/apple-computer-founded)

## Present Day

In the present day, Apple is behind in the utilization of Generative AI, whilst other companies have already began implementing it. However, Apple still utilizes AI in a variety of ways, and has ever since the development of iOS 15.

Some of the current utilization of AI in Apple products are:
- Live Text
- Predictive Text
- Photography Smarts
- Personal Voice

### Live Text
In 2021, iOS 15 and later released a front-facing AI feature for iPhones, this feature is known as **Live Text**. Live text is a computer vision tool that recognizes either hand-written or type-written text in photos that a user takes. This AI developmennt allows for someone to copy and paste the specified text from the photo into any note-taking app with just a few taps or swipes of the finger.
> "Live Text can come in handy in day-to-day life. Say you had a hand-written recipe you wanted to digitize. After taking a photo of that recipe . . . you could copy and paste that text into a Word document, for instance, and save it as a digital backup." 
> ([CNET](https://www.cnet.com/tech/mobile/apple-already-has-ai-powered-features-on-your-iphone-heres-how-to-use-them/))
### Predictive Text
With the recent software update/release of iOS 17, Apple fixed one of the biggest gripes that existed in apple products such as the previously mentioned iPhone, Autocorrect. With this update users no longer have to worry about their foul language being censored to 'Duck' or 'Shut'. Beyond that update, autocorrect can now fix mistakes more accurately and serves up more customized inline **Predictive Text**.
> "Much of this improvement is credited to iOS 17's new transformer language odel, which uses machine learning for word prediction . . . It has been trained by troves of data, allowing it to learn context and patterns to provide improved results, or in this case the ability to replicate how humans sound." 
> ([CNET](https://www.cnet.com/tech/mobile/apple-already-has-ai-powered-features-on-your-iphone-heres-how-to-use-them/))
### Photography Smarts
It is known that the iPhone relies on advanced algorithms and computational photogrraphy for a large portion of it's camera features. One such feature is **Portrait Mode**.
> "Portrait Mode . . . uses AI to identify subjects and creates a **bokeh effect**."
> ([CNET](https://www.cnet.com/tech/mobile/apple-already-has-ai-powered-features-on-your-iphone-heres-how-to-use-them/))
>> "Bokeh is defined as "the effect of a soft out-of-focus background that you get when shooting a subject. . . Simply put, bokeh is the pleasing or aesthetic quality of out-of-focus blur in a photograph"
>> ([Nikon](https://www.nikonusa.com/learn-and-explore/c/tips-and-techniques/bokeh-for-beginners))

There are also some other functionalities that utilize AI in the camera app of the iPhone, such as **Cinematic Mode**.

> ". . . uses AI to simulate the desired aperture and dynamically adjusts focus to keep your moving subject smart."

Lastly, now with iOS 17, one of the newer AI-powered capabilities is the photo app's ability to identify pets in a photo. This allows for better photo organization.
### Personal Voice